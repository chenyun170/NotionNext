// /api/chat.js
import OpenAI from "openai";

export default async function handler(req, res) {
  // 1. å®‰å…¨æ£€æŸ¥
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // 2. é…ç½®æ–°çš„æ¥å£åœ°å€ (ä»ä½ çš„DevToolsæˆªå›¾æå–)
  const client = new OpenAI({
    apiKey: "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", // å¯¹åº”æˆªå›¾é‡Œçš„ API Token
    baseURL: "https://api-proxy.de/openai/v1", // âœ… æˆªå›¾3é‡Œçš„çœŸå®åœ°å€
  });

  try {
    const { message } = req.body;

    // 3. å‘èµ·æµå¼è¯·æ±‚ (è¿™æ˜¯æœ€å…³é”®çš„ä¸€æ­¥)
    const stream = await client.chat.completions.create({
      // âš ï¸ é‡ç‚¹ï¼šæ¨¡å‹åå­—ã€‚å»ºè®®å…ˆå¡«æˆªå›¾ç¤ºä¾‹é‡Œçš„ "gpt-4.1-mini" è¯•è¯•
      // å¦‚æœæŠ¥é”™ 404ï¼Œå°±æ”¹æˆ "glm-4" æˆ– "[Z] GLM-4.7"
      model: "gpt-4.1-mini-2025-04-14", 
      
      messages: [
        { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ã€‚" },
        { role: "user", content: message }
      ],
      
      // âœ… æˆªå›¾å¼ºåˆ¶è¦æ±‚ï¼šå¿…é¡»å¼€å¯æµå¼
      stream: true, 
      
      // ğŸ’¡ å¯é€‰å‚æ•°ï¼šæ ¹æ®æˆªå›¾ï¼Œfalse ä»£è¡¨æ ‡å‡† OpenAI æµï¼Œè¿™æ­£å¥½å…¼å®¹ SDK
      // å¦‚æœ SDK æŠ¥é”™ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨åŠ  extra_body: { onlyText: false }
    });

    // 4. åç«¯æ‹¼æ¥æµæ•°æ®
    // å› ä¸ºæ¥å£å¼ºåˆ¶æµå¼ï¼Œä½†ä½ çš„å‰ç«¯å¯èƒ½è¿˜åœ¨ç­‰ä¸€ä¸ªå®Œæ•´çš„ JSON
    // æ‰€ä»¥æˆ‘ä»¬åœ¨æœåŠ¡å™¨ç«¯æŠŠæµâ€œæ¥å®Œâ€ï¼Œæ‹¼æˆä¸€æ•´å¥è¯
    let fullContent = "";
    
    for await (const chunk of stream) {
      // å–å‡ºæ¯ä¸€å°å—çš„å†…å®¹ï¼Œæ‹¼æ¥åˆ°å¤§å­—ç¬¦ä¸²é‡Œ
      const content = chunk.choices[0]?.delta?.content || "";
      fullContent += content;
    }

    // 5. æ‹¼è£…å®Œæˆï¼Œä¸€æ¬¡æ€§è¿”å›ç»™å‰ç«¯
    res.status(200).json({ result: fullContent });

  } catch (error) {
    console.error("APIè°ƒç”¨å¤±è´¥:", error);
    res.status(500).json({ error: error.message || error.toString() });
  }
}
